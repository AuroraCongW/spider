{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "key_words = [\"U.S.-China trade and COVID-19\",\"Unfair trade and intellectual property rights\",\"U.S.-China trade and tariffs\",\"U.S.-China trade war and trade barriers\",\"U.S.-China trade war and protectionism\",\"China and the world order\",\"China and national Security\",\"presidential election and trade war\"]\n",
    "\n",
    "key_words_number = len(key_words)\n",
    "\n",
    "websites = [\"Huffpost\",\"the Washington Post\",\"Fox News\",\"Wall Street journal\"]\n",
    "\n",
    "websites_number = len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_number_info():\n",
    "    for i in range(websites_number):\n",
    "        print()\n",
    "        print(\"Website:\",websites[i])\n",
    "        print()\n",
    "        for j in range(key_words_number):\n",
    "            file_path = \"~/data/data_%s_%s.json\"%(websites[i],key_words[j])\n",
    "            data = pd.read_json(file_path)\n",
    "            print(\"Keywords:%s Number: %s\"%(key_words[j],len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_website(website):\n",
    "    pieces = []\n",
    "    for i in range(key_words_number):\n",
    "        file_path = \"~/data/data_%s_%s.json\"%(website,key_words[i])\n",
    "        frame = pd.read_json(file_path)\n",
    "        pieces.append(frame)\n",
    "    data = pd.concat(pieces, ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congw/anaconda3/lib/python3.7/site-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname ET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    }
   ],
   "source": [
    "websites_merge_data = []\n",
    "for website in websites:\n",
    "    data = merge_data_website(website).drop_duplicates(['content'])\n",
    "    websites_merge_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_transform(x):\n",
    "    start = datetime(2020, 8, 1)\n",
    "    if x.split()[-1]==\"ago\":\n",
    "        days_ago = x.split()[0]\n",
    "        date_str = start-timedelta(int(days_ago))\n",
    "        return date_str\n",
    "    else:\n",
    "        return parse(x)\n",
    "\n",
    "websites_merge_data[2].date = websites_merge_data[2].date.map(time_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(start='20200701', periods=31, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_week(website):\n",
    "    return website.set_index('date').resample('W-SUN').count().url.reset_index()\n",
    "\n",
    "count_weeks=[]\n",
    "for i in range(websites_number):\n",
    "    CW = count_week(websites_merge_data[i]).rename(columns={\"url\":\"number\"})\n",
    "    count_weeks.append(CW)\n",
    "\n",
    "def topic_count_week(website):\n",
    "    return website.set_index('date').groupby('topic').resample('W-SUN').count().url.reset_index()\n",
    "\n",
    "count_topic_weeks=[]\n",
    "for i in range(websites_number):\n",
    "    CTW = topic_count_week(websites_merge_data[i]).rename(columns={\"url\":\"number\"})\n",
    "    count_topic_weeks.append(CTW)\n",
    "\n",
    "# for i in range(websites_number):\n",
    "#     count_weeks[i] = count_weeks[i].set_index('date')\n",
    "#     count_topic_weeks[i] = count_topic_weeks[i].set_index('date')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dn = pd.merge(pd.merge(pd.merge(count_weeks[0],count_weeks[1],on='date'),count_weeks[2],on='date'),count_weeks[3],on='date')\n",
    "\n",
    "dn.columns = [\"date\"]+websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range=['7.1-7.5','7.6-7.12','7.13-7.19','7.20-7.26','7.27-7.31']\n",
    "\n",
    "dn = dn.set_axis(date_range)\n",
    "\n",
    "dn = dn.drop('date',axis=1)\n",
    "\n",
    "dn.plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(df):\n",
    "    return df.set_index(['date','topic']).unstack().fillna(0)['number']\n",
    "\n",
    "change_format(count_topic_weeks[0]).to_excel(\"e.xlsx\")\n",
    "\n",
    "for i,df in enumerate(count_topic_weeks):\n",
    "    change_format(df).to_excel(\"Topic-%s.xlsx\"%websites[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "f = open(u'txt/AliceEN.txt','r').read()\n",
    "wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2).generate(f)\n",
    "\n",
    "# width,height,margin可以设置图片属性\n",
    "\n",
    "# generate 可以对全部文本进行自动分词,但是他对中文支持不好,对中文的分词处理请看我的下一篇文章\n",
    "#wordcloud = WordCloud(font_path = r'D:\\Fonts\\simkai.ttf').generate(f)\n",
    "# 你可以通过font_path参数来设置字体集\n",
    "\n",
    "#background_color参数为设置背景颜色,默认颜色为黑色\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "wordcloud.to_file('test.png')\n",
    "# 保存图片,但是在第三模块的例子中 图片大小将会按照 mask 保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
